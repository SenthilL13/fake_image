{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42b0ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import itertools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93b8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57589b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42101560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0f85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bba4f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CRW_4809_scale.jpg'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [\"CRW_4809_scale.jpg\"]\n",
    "listToStr = ' '.join([str(img) for img in s])\n",
    "listToStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97599dae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7396\\1962403905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "plt.imread(path+\"/\"+img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9da2de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:7000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [25/Mar/2023 04:06:43] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000254963DD1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 489ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000254963DDB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Mar/2023 04:07:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Mar/2023 04:08:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = joblib.load('dt.pkl')\n",
    "path = \"C:/Users/purajith/Downloads/MICC-F220\"\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    '''\n",
    "    For rendering results on HTML GUI\n",
    "    '''\n",
    "    int_features = [(x) for x in request.form.values()]\n",
    "    image1 = ' '.join([str(img) for img in s])\n",
    "\n",
    "    img = str(path)+\"/\"+str(image1)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def ela(img):\n",
    "        def convert_to_ela_image(path, quality):\n",
    "\n",
    "            temp_filename = 'temp_file_name.jpg'\n",
    "            ela_filename = 'temp_ela.png'\n",
    "\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            image.save(temp_filename, 'JPEG', quality = quality)\n",
    "            temp_image = Image.open(temp_filename)\n",
    "\n",
    "            ela_image = ImageChops.difference(image, temp_image)\n",
    "\n",
    "            extrema = ela_image.getextrema()\n",
    "            max_diff = max([ex[1] for ex in extrema])\n",
    "            if max_diff == 0:\n",
    "                max_diff = 1\n",
    "            scale = 255.0 / max_diff\n",
    "\n",
    "            ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "            return ela_image\n",
    "        def prepare_image(img):\n",
    "            return np.array(convert_to_ela_image(img, 90).resize(image_size)).flatten() / 255.0\n",
    "    #    image_path= 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n",
    "        image_size = (128, 128)\n",
    "\n",
    "        X = prepare_image(img)\n",
    "        X = np.array(X)\n",
    "        X = X.reshape(-1, 128, 128, 3)\n",
    "\n",
    "\n",
    "        class_names = ['fake', 'real']\n",
    "        import tensorflow as tf\n",
    "        from tensorflow.keras.models import load_model\n",
    "        classifierLoad = tf.keras.models.load_model('model_casia_run1.h5')\n",
    "\n",
    "\n",
    "    #    real_image_path = 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n",
    "        image = prepare_image(img)\n",
    "        image = image.reshape(-1, 128, 128, 3)\n",
    "        y_pred = classifierLoad.predict(image)\n",
    "        y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
    "        result_ela = class_names[y_pred_class]\n",
    "        ela_score = np.amax(y_pred)\n",
    "        return result_ela, ela_score\n",
    "    result = ela(img)\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    def forged(img):\n",
    "        classifierLoad = tf.keras.models.load_model('forge.h5')\n",
    "        imgage = 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n",
    "\n",
    "        test_image=image.load_img(img,target_size=(128,128))\n",
    "\n",
    "        #img = plt.imshow(test_image)\n",
    "\n",
    "        test_image=image.img_to_array(test_image)\n",
    "\n",
    "        test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "        result = classifierLoad.predict(test_image)\n",
    "\n",
    "        prediction = result[0]\n",
    "\n",
    "\n",
    "\n",
    "        prediction=list(prediction)\n",
    "\n",
    "        prediction\n",
    "\n",
    "        classes  = ['real', 'fake']\n",
    "        output=zip(classes,prediction)\n",
    "\n",
    "        output=dict(output)\n",
    "\n",
    "        output\n",
    "\n",
    "        if output['real']==1.0 :\n",
    "            copy_move = \"real\"\n",
    "        else:\n",
    "            copy_move = \"fake\"\n",
    "        return  copy_move\n",
    "\n",
    "    result = ela(img)\n",
    "\n",
    "    if forged(img) != \"real\":\n",
    "        result = \"fake\"\n",
    "    elif result[0] != \"real\":\n",
    "        result = \"fake\"\n",
    "    else:\n",
    "        result = \"Original\"\n",
    "\n",
    "\n",
    "    \n",
    "    return render_template('index.html', prediction_text='The result is  {}'.format(result))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"localhost\", port=7000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba692171",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f32e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0e951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6fae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3debe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "def forged(img):\n",
    "    classifierLoad = tf.keras.models.load_model('forge.h5')\n",
    "    imgage = 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n",
    "\n",
    "    test_image=image.load_img(img,target_size=(128,128))\n",
    "\n",
    "    #img = plt.imshow(test_image)\n",
    "\n",
    "    test_image=image.img_to_array(test_image)\n",
    "\n",
    "    test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "    result = classifierLoad.predict(test_image)\n",
    "\n",
    "    prediction = result[0]\n",
    "\n",
    "\n",
    "\n",
    "    prediction=list(prediction)\n",
    "\n",
    "    prediction\n",
    "\n",
    "    classes  = ['real', 'fake']\n",
    "    output=zip(classes,prediction)\n",
    "\n",
    "    output=dict(output)\n",
    "\n",
    "    output\n",
    "\n",
    "    if output['real']==1.0 :\n",
    "        copy_move = \"real\"\n",
    "    else:\n",
    "        copy_move = \"fake\"\n",
    "    return  copy_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'C:/Users/purajith/Downloads/casia/CASIA2/Au/Au_ani_00001.jpg'\n",
    "result = ela(img)\n",
    "\n",
    "if forged(img) != \"real\":\n",
    "    result = \"fake\"\n",
    "elif result[0] != \"real\":\n",
    "    result = \"fake\"\n",
    "else:\n",
    "    result = \"Original\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b01d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faebffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
