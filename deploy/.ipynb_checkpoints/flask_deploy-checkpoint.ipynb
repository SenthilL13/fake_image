{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25781eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:7000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [29/Mar/2023 22:43:44] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real_00246.jpg']\n",
      "['real_00246.jpg']\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.44701895, 0.552981]\n",
      "output {'fake': 0.44701895, 'real': 0.552981}\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:43:51] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 55.30\n",
      "check real\n",
      "['easy_100_1111.jpg']\n",
      "['easy_100_1111.jpg']\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.42881787, 0.5711822]\n",
      "output {'fake': 0.42881787, 'real': 0.5711822}\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:43:58] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 57.12\n",
      "check real\n",
      "['easy_98_0001.jpg']\n",
      "['easy_98_0001.jpg']\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.36194083, 0.63805914]\n",
      "output {'fake': 0.36194083, 'real': 0.63805914}\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:44:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 63.81\n",
      "check real\n",
      "['easy_99_0101.jpg']\n",
      "['easy_99_0101.jpg']\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.34297255, 0.6570274]\n",
      "output {'fake': 0.34297255, 'real': 0.6570274}\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:44:12] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 65.70\n",
      "check real\n",
      "['easy_101_0010.jpg']\n",
      "['easy_101_0010.jpg']\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B3B9AC9AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.5086358, 0.49136412]\n",
      "output {'fake': 0.5086358, 'real': 0.49136412}\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:44:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: fake Confidence: 50.86\n",
      "check fake\n",
      "['easy_104_1000.jpg']\n",
      "['easy_104_1000.jpg']\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B38F1D9DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.44916806, 0.550832]\n",
      "output {'fake': 0.44916806, 'real': 0.550832}\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:44:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 55.08\n",
      "check real\n",
      "['real_00251.jpg']\n",
      "['real_00251.jpg']\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "classes ['fake', 'real']\n",
      "prediction [0.41587216, 0.5841279]\n",
      "output {'fake': 0.41587216, 'real': 0.5841279}\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Mar/2023 22:44:37] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real Confidence: 58.41\n",
      "check real\n"
     ]
    }
   ],
   "source": [
    "##### from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "\n",
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image\n",
    "image_size = (128, 128)\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0\n",
    "app = Flask(__name__)\n",
    "tf.keras.models.load_model('fake.h5')\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict():\n",
    "    '''\n",
    "    For rendering results on HTML GUI\n",
    "    '''\n",
    "    int_features = [(x) for x in request.form.values()]\n",
    "    final_features = int_features\n",
    "    print(final_features)\n",
    "    img = final_features\n",
    "    print(img)\n",
    "\n",
    "#    classifierLoad = tf.keras.models.load_model('detector.h5')\n",
    "    classifierLoad = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "    \n",
    "    image_path = \"testing/\"+img[0]\n",
    "    image = prepare_image(image_path)\n",
    "    image = image.reshape(-1, 128, 128, 3)\n",
    "\n",
    "    result = classifierLoad.predict(image)\n",
    "\n",
    "    prediction = result[0]\n",
    "\n",
    "    classes = [\"fake\", \"real\"]\n",
    "\n",
    "    print(\"classes\",classes)\n",
    "\n",
    "    prediction=list(prediction)\n",
    "\n",
    "    prediction\n",
    "    print(\"prediction\",prediction)\n",
    "\n",
    "\n",
    "    output=zip(classes,prediction)\n",
    "\n",
    "    output=dict(output)\n",
    "    print(\"output\",output)\n",
    "    \n",
    "# accuracy\n",
    "    class_names = ['fake', 'real']\n",
    "    image_path1 = \"testing/\"+img[0]\n",
    "    image1 = prepare_image(image_path1)\n",
    "    image1 = image1.reshape(-1, 128, 128, 3)\n",
    "    y_pred = classifierLoad.predict(image1)\n",
    "    y_pred_class = np.argmax(y_pred, axis = 1)[0]\n",
    "    print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n",
    "    print(\"check\",class_names[y_pred_class])\n",
    "    \n",
    "    \n",
    "# final prediction    \n",
    "    if class_names[y_pred_class]==\"fake\":\n",
    "        res = \"Fake \"\n",
    "        acry = np.amax(y_pred) * 100\n",
    "    elif class_names[y_pred_class]==\"real\":\n",
    "        res =\"Real\"\n",
    "        acry = np.amax(y_pred) * 100\n",
    "\n",
    "    return render_template('index.html', prediction_text=' Image  Status :  {}'.format(res),accuracy='Image Accuracy :  {}'.format(np.amax(y_pred) * 100))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"localhost\", port=7000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af6bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
